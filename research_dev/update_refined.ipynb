{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Financial News Sentiment Analysis\n",
        "\n",
        "This notebook performs sentiment classification (bullish, neutral, bearish) on financial news using:\n",
        "1. GMI API (DeepSeek-V3.2) as baseline\n",
        "2. Two pre-trained transformer models for comparison\n",
        "3. Fine-tuning the best model\n",
        "4. Re-evaluation after fine-tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!uv add datasets transformers torch requests pandas scikit-learn tqdm -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
        "\n",
        "DATASET_NAME = \"ArthurMrv/EDGAR-CORPUS-Financial-Summarization-Labeled\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Successfully logged in to Hugging Face Hub!\n"
          ]
        }
      ],
      "source": [
        "# Authenticate with Hugging Face Hub\n",
        "from huggingface_hub import login\n",
        "import getpass\n",
        "\n",
        "login(token=HF_TOKEN)\n",
        "\n",
        "print(\"\\nSuccessfully logged in to Hugging Face Hub!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b3c904fc8ac4bacb9ff314d8dfebddd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75459b8109e74f878c67a69e2d1fc1f6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "data/refined-00000-of-00002.parquet:   0%|          | 0.00/161M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03dd57061f4b4ef3ba73c3dbf65adf32",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating refined split:   0%|          | 0/10313 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_hash', 'input', 'summary', 'model', 'llm_sentiment_class', 'llm_sentiment_model', 'llm_sentiment_rationale'],\n",
              "    num_rows: 10313\n",
              "})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Load in streaming mode\n",
        "ds = load_dataset(DATASET_NAME, split=\"refined\")\n",
        "ds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input_hash</th>\n",
              "      <th>input</th>\n",
              "      <th>summary</th>\n",
              "      <th>model</th>\n",
              "      <th>llm_sentiment_class</th>\n",
              "      <th>llm_sentiment_model</th>\n",
              "      <th>llm_sentiment_rationale</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5e86b75638298802943dcc20093fae925be0c5146cbbf5...</td>\n",
              "      <td>FINANCIAL STATEMENTS AND SUPPLEMENTARY DATA IN...</td>\n",
              "      <td>Here's a summary of the financial statement:\\n...</td>\n",
              "      <td>Claude</td>\n",
              "      <td>-1</td>\n",
              "      <td>DeepSeek-V3.2</td>\n",
              "      <td>the text explicitly states the company is \"ope...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>c5b4129b8c9c94491f949c87ac452f30af0f11b8a68e5d...</td>\n",
              "      <td>FINANCIAL STATEMENTS AND SUPPLEMENTARY DATA.  ...</td>\n",
              "      <td>Based on the provided excerpt, here's a summar...</td>\n",
              "      <td>Claude</td>\n",
              "      <td>-2</td>\n",
              "      <td>DeepSeek-V3.2</td>\n",
              "      <td>the text explicitly describes \"ongoing financi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a488c022380bcf59d4d3c99127ed2554fa67f86854119e...</td>\n",
              "      <td>. Report of Independent Registered Public Acco...</td>\n",
              "      <td>This appears to be a partial financial stateme...</td>\n",
              "      <td>Claude</td>\n",
              "      <td>0</td>\n",
              "      <td>DeepSeek-V3.2</td>\n",
              "      <td>the text is purely descriptive of accounting p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>52db0b9f1bfe2db5807d09128d511e2176c0226e0558c7...</td>\n",
              "      <td>Index to Consolidated Financial Statements All...</td>\n",
              "      <td>This appears to be a partial financial stateme...</td>\n",
              "      <td>Claude</td>\n",
              "      <td>0</td>\n",
              "      <td>DeepSeek-V3.2</td>\n",
              "      <td>the text is a purely factual description of ac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a5d562bb3069324a9facf4ecb6fdf52aee051460a2cecf...</td>\n",
              "      <td>.  ACCOUNTING FIRM To the Board of Directors a...</td>\n",
              "      <td>Here's a summary of the financial statement:\\n...</td>\n",
              "      <td>Claude</td>\n",
              "      <td>0</td>\n",
              "      <td>DeepSeek-V3.2</td>\n",
              "      <td>the text is a purely factual, neutral descript...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          input_hash  \\\n",
              "0  5e86b75638298802943dcc20093fae925be0c5146cbbf5...   \n",
              "1  c5b4129b8c9c94491f949c87ac452f30af0f11b8a68e5d...   \n",
              "2  a488c022380bcf59d4d3c99127ed2554fa67f86854119e...   \n",
              "3  52db0b9f1bfe2db5807d09128d511e2176c0226e0558c7...   \n",
              "4  a5d562bb3069324a9facf4ecb6fdf52aee051460a2cecf...   \n",
              "\n",
              "                                               input  \\\n",
              "0  FINANCIAL STATEMENTS AND SUPPLEMENTARY DATA IN...   \n",
              "1  FINANCIAL STATEMENTS AND SUPPLEMENTARY DATA.  ...   \n",
              "2  . Report of Independent Registered Public Acco...   \n",
              "3  Index to Consolidated Financial Statements All...   \n",
              "4  .  ACCOUNTING FIRM To the Board of Directors a...   \n",
              "\n",
              "                                             summary   model  \\\n",
              "0  Here's a summary of the financial statement:\\n...  Claude   \n",
              "1  Based on the provided excerpt, here's a summar...  Claude   \n",
              "2  This appears to be a partial financial stateme...  Claude   \n",
              "3  This appears to be a partial financial stateme...  Claude   \n",
              "4  Here's a summary of the financial statement:\\n...  Claude   \n",
              "\n",
              "  llm_sentiment_class llm_sentiment_model  \\\n",
              "0                  -1       DeepSeek-V3.2   \n",
              "1                  -2       DeepSeek-V3.2   \n",
              "2                   0       DeepSeek-V3.2   \n",
              "3                   0       DeepSeek-V3.2   \n",
              "4                   0       DeepSeek-V3.2   \n",
              "\n",
              "                             llm_sentiment_rationale  \n",
              "0  the text explicitly states the company is \"ope...  \n",
              "1  the text explicitly describes \"ongoing financi...  \n",
              "2  the text is purely descriptive of accounting p...  \n",
              "3  the text is a purely factual description of ac...  \n",
              "4  the text is a purely factual, neutral descript...  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = ds.to_pandas()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Setup API for Classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from huggingface_hub import InferenceClient\n",
        "\n",
        "client = InferenceClient(\n",
        "    api_key=HF_TOKEN,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def request_sentiment(text, prompt_template):\n",
        "    prompt = prompt_template.format(input_text=text)\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"deepseek-ai/DeepSeek-V3.2\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "    )\n",
        "    response = completion.choices[0].message\n",
        "    # Extract the word (expected to be only the class label)\n",
        "    return response.content.strip().lower()\n",
        "\n",
        "def get_llm_sentiment(df, input_column, output_column, prompt_template):\n",
        "    \"\"\"\n",
        "    Given a DataFrame, input column, and output column name,\n",
        "    calls the DeepSeek LLM via Hugging Face Inference API to get the sentiment for each row.\n",
        "    The result will be stored in a new column (output_column).\n",
        "    \"\"\"\n",
        "\n",
        "    tqdm.pandas(desc=\"Classifying sentiment\")\n",
        "    df[output_column] = df[input_column].progress_apply(lambda x: request_sentiment(x, prompt_template))\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt_template = \"\"\"\n",
        "You are a Financial News Sentiment Classifier.\n",
        "Your task is to classify the sentiment EXPLICITLY expressed in the text regarding stocks.\n",
        "\n",
        "### Scoring Rubric:\n",
        "+2 (Highly Bullish): Text explicitly states prices are soaring, skyrocketing, or reports massive success/breakthroughs.\n",
        "+1 (Bullish): Text describes price increases, positive outlooks, or favorable conditions.\n",
        " 0 (Neutral): Text is purely factual with no emotional charge, or describes flat price movement.\n",
        "-1 (Bearish): Text describes price drops, fears, negative outlooks, or unfavorable conditions.\n",
        "-2 (Highly Bearish): Text explicitly states prices are crashing, plummeting, or reports crisis/panic.\n",
        "\n",
        "### Critical Rules:\n",
        "1. **React to the text, not the market.** If the text says \"stocks are down,\" the score MUST be negative, even if the reason is generic (like the FED).\n",
        "2. Do not assume news is \"priced in.\" Analyze the immediate emotional and factual content of the snippet.\n",
        "3. Ignore external context. Only use the provided text.\n",
        "\n",
        "### Output Format:\n",
        "Reasoning: [1 sentence identifying the specific keywords or claims in the text that justify the score]\n",
        "Score: [Integer between -2 and 2]\n",
        "\n",
        "---\n",
        "Article: {input_text}\n",
        "\"\"\"\n",
        "input_column = \"summary\"\n",
        "output_column = \"llm_output\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'reasoning: the text explicitly describes the company as \"operating at a loss with a working capital deficit\" and highlights \"substantial concerns about the company\\'s ability to continue operations,\" which are highly negative and unfavorable conditions.  \\nscore: -2'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_txt = \"\"\"\n",
        "Here's a summary of the financial statement: Financial Health Overview: - The company (Digerati) is operating at a loss with a working capital deficit - There are substantial concerns about the company's ability to continue operations - Management has addressed these concerns in Note 2 Revenue Streams: 1. Global VoIP Services - Provides VoIP services to U.S. and foreign telecommunications companies - Focuses on markets in Mexico, Asia, the Middle East, and Latin America 2. Cloud Communication Services - Offers hosted IP/PBX services to resellers and enterprise customers - Includes various features like call center applications, prepaid services, and customized IP/PBX features Key Expenses: - Transmission and termination charges from suppliers - Infrastructure and network costs - Internet bandwidth charges - Licensing and co-location charges - Installation costs Financial Risk Factors: - Credit risk from trade receivables - Potential exposure from bank deposits exceeding federally insured limits - Customer concentration risk (four customers comprise 20% of revenue) Revenue Recognition: - Based on evidence of arrangement, service delivery, fixed pricing, and collectability - Company acts as primary obligor with pricing authority and credit risk responsibility This statement indicates a company with established revenue streams but facing significant financial challenges and operational risks.\"\"\"\n",
        "request_sentiment(input_txt, prompt_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows with no sentiment class: 6034\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input_hash</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2683</th>\n",
              "      <td>93fed708cdd40a6d913f9f66c5a72d54c356d0aa16669d...</td>\n",
              "      <td>I apologize, but the text you've provided appe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4215</th>\n",
              "      <td>949e9c240eb4e75485e6c19ba7628f244323ee3fc6a827...</td>\n",
              "      <td>The financial statement provided includes info...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4281</th>\n",
              "      <td>c5b418da48cbefe7d4cca8a74eb87b28a0df20b504d913...</td>\n",
              "      <td>The financial statement provided includes info...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4282</th>\n",
              "      <td>b44b7a4f86a4130c03963f4b207253c15926fd45c7a86b...</td>\n",
              "      <td>Here's a summary of the financial statement:\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4283</th>\n",
              "      <td>c758f909196698d45e8303d6795214c8fd43926caabc9f...</td>\n",
              "      <td>The financial statement provided includes info...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             input_hash  \\\n",
              "2683  93fed708cdd40a6d913f9f66c5a72d54c356d0aa16669d...   \n",
              "4215  949e9c240eb4e75485e6c19ba7628f244323ee3fc6a827...   \n",
              "4281  c5b418da48cbefe7d4cca8a74eb87b28a0df20b504d913...   \n",
              "4282  b44b7a4f86a4130c03963f4b207253c15926fd45c7a86b...   \n",
              "4283  c758f909196698d45e8303d6795214c8fd43926caabc9f...   \n",
              "\n",
              "                                                summary  \n",
              "2683  I apologize, but the text you've provided appe...  \n",
              "4215  The financial statement provided includes info...  \n",
              "4281  The financial statement provided includes info...  \n",
              "4282  Here's a summary of the financial statement:\\n...  \n",
              "4283  The financial statement provided includes info...  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_subset_llm = df[df[\"llm_sentiment_class\"].isna()][[\"input_hash\", \"summary\"]]\n",
        "print(f\"Number of rows with no sentiment class: {len(df_subset_llm)}\")\n",
        "\n",
        "\n",
        "df_subset_llm = df_subset_llm[[\"input_hash\", \"summary\"]]\n",
        "df_subset_llm.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9b4a07bce6145cba6416a7a28e717c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/3t/ylx1j6z50zx7nf97vl6_sts00000gn/T/ipykernel_24163/1499718439.py:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[output_column] = df[input_column].progress_apply(lambda x: request_sentiment(x, prompt_template))\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input_hash</th>\n",
              "      <th>summary</th>\n",
              "      <th>llm_output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2683</th>\n",
              "      <td>93fed708cdd40a6d913f9f66c5a72d54c356d0aa16669d...</td>\n",
              "      <td>I apologize, but the text you've provided appe...</td>\n",
              "      <td>reasoning: the text is a meta-statement about ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4215</th>\n",
              "      <td>949e9c240eb4e75485e6c19ba7628f244323ee3fc6a827...</td>\n",
              "      <td>The financial statement provided includes info...</td>\n",
              "      <td>reasoning: the text is a purely factual descri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4281</th>\n",
              "      <td>c5b418da48cbefe7d4cca8a74eb87b28a0df20b504d913...</td>\n",
              "      <td>The financial statement provided includes info...</td>\n",
              "      <td>reasoning: the text explicitly states the comp...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             input_hash  \\\n",
              "2683  93fed708cdd40a6d913f9f66c5a72d54c356d0aa16669d...   \n",
              "4215  949e9c240eb4e75485e6c19ba7628f244323ee3fc6a827...   \n",
              "4281  c5b418da48cbefe7d4cca8a74eb87b28a0df20b504d913...   \n",
              "\n",
              "                                                summary  \\\n",
              "2683  I apologize, but the text you've provided appe...   \n",
              "4215  The financial statement provided includes info...   \n",
              "4281  The financial statement provided includes info...   \n",
              "\n",
              "                                             llm_output  \n",
              "2683  reasoning: the text is a meta-statement about ...  \n",
              "4215  reasoning: the text is a purely factual descri...  \n",
              "4281  reasoning: the text explicitly states the comp...  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# do test with 3 rows\n",
        "test_df_subset_llm = df_subset_llm.head(3)\n",
        "test_output_df_subset_llm = get_llm_sentiment(test_df_subset_llm, input_column, output_column, prompt_template)\n",
        "test_output_df_subset_llm.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a9fefb6f3f448e088e40fc8e66a30c7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 1/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2560deb21523465c9b19349e85c0bc1e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempt 1 failed for batch 2/61, sleeping for 10 seconds\n",
            "Error: 504 Server Error: Gateway Time-out for url: https://router.huggingface.co/novita/v3/openai/chat/completions\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd4fc6d68d5a4fd492c484f7f2b764cb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempt 2 failed for batch 2/61, sleeping for 10 seconds\n",
            "Error: 504 Server Error: Gateway Time-out for url: https://router.huggingface.co/novita/v3/openai/chat/completions\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b5ac697718b4009a7e985d47ec74959",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 2/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "019db0521c9e433aac8ee12f6609af71",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 3/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0dd981b451024eb5975830477dcd5392",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 4/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b73262340f24f5eafc604140525ead3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 5/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e12564dbd624f2b99328efd36f73e07",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 6/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a7a9f57445142548eaac17bf8f22af6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 7/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b31b0401eb946af85406acb4a0dcf05",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 8/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3703ef9189dc4ff0b31b33a57b531319",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 9/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44be09a8492b49b0806a9c6fd3115af2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempt 1 failed for batch 10/61, sleeping for 10 seconds\n",
            "Error: 504 Server Error: Gateway Time-out for url: https://router.huggingface.co/novita/v3/openai/chat/completions\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "425fa7bd8cf04873bc8ac17b9036ff78",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 10/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9971556933234efcbb158175e8245f3d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 11/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73ecd6686f9b4da7ab657a3102f91c8e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 12/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f57643a53c6451083639a2c0e3651ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 13/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7106da3968a48389b5ceff6374c1e8a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 14/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89b3cb0e4ec049b2bc9438e07df6803f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 15/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50780397b49a4e569948ef98c08d472c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempt 1 failed for batch 16/61, sleeping for 10 seconds\n",
            "Error: 504 Server Error: Gateway Time-out for url: https://router.huggingface.co/novita/v3/openai/chat/completions\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b15143d51d748099a43359fb5841b95",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 16/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49923091b88c41c1818922af9b895f29",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 17/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d623cff653754bf79f3e912dcca7467b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 18/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37ec26dc27d34f04bf89ae2649ab056f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 19/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "900530859d5a4767a2303838f4ae17b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 20/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2b633053b414e85a1ba0230c773f66a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 21/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47c55a29c9f743099aaf61f00d030376",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 22/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12d669d0fd2640ba9657f0e04910c517",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 23/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ded441f14b1e4357aa28affb7a4d52ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 24/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b302b92811d43bca0703dc91aa17613",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 25/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "568181750dfe471e98c87c8f3f165ea7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 26/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b537566a6454857bd174a9f6a01a63a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 27/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae3647f5cbf84de9a45eda41e9c50869",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 28/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90c5cbce807a47b6867e926ea2cc8159",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 29/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1785f9c7182f4a77bef70f24794c53a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 30/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d58171856b84b07a88730241b049b1c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 31/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d92b80918dce4658befb6ad989b39f9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 32/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5eadadadab3b4d49b9ad4cd3e8ce50af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 33/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70549ef639384c41b3bdbbeacbd8cb28",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 34/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92d4b0ae11094753ab538f8355149543",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 35/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a4fbbb603fd4ca7a13772906bad4a52",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 36/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afd18bb1546247dfa3e0a040e38557b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 37/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78d2c1fbc71a43f2b864788197cf6cbb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 38/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7810ebe1e4714b04a2bf06287fe38d3a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 39/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "364ec1681897453ebf2af67decb7a954",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 40/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4de69d6030cb45fd872e4496affdee1e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 41/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0136d29a42044ba9b809db56d5477003",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 42/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dbbb5a1786cb464a88beb32dc10550e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 43/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2792cfefa5234dd3aacd56f39ebceb9c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 44/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86be457a44fb494688033ab9d5fba64e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 45/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6611970a0304059859c2f672b9cae62",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 46/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99e3254f56194d1db1580bd44eb5418c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 47/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6025bb017da45e3af8b71d8943e92fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 48/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "66475e4639954e5e8d2072d7630e9499",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 49/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37d2f1d5ce864c66ad1c383eadbc2c12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 50/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c91b8519f4b4fe08c1b6e9c09ace514",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 51/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2574689d776407496e2517b36ce212d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 52/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18db49855fea41f0ab800989a6c3674a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 53/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a4d6483de94440db36449c1a9330f56",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 54/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20be11d69d564aa8a67f034831e0640b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 55/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8466ffff70dc4957b8508b7267415f96",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 56/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ab088ed49ff4e36861e6ab47b7ad217",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 57/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3bae96aa1b4943b7b5e85ae7c1378392",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 58/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b3c22e0751a488ba9008d1ab2f52589",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 59/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6ff912947ce4243a5afaac09f203d86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 60/61 locally.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4188159cea1445a09fe2cf50a16ff15d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/34 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved batch 61/61 locally.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "from datasets import Dataset, load_dataset, DatasetDict\n",
        "from huggingface_hub import HfApi, HfFolder\n",
        "import math\n",
        "\n",
        "import time\n",
        "\n",
        "\n",
        "batch_size = 100\n",
        "n_rows = len(df_subset_llm)\n",
        "n_batches = math.ceil(n_rows / batch_size)\n",
        "\n",
        "api = HfApi(\n",
        "    token=HF_TOKEN\n",
        ")\n",
        "\n",
        "# 1. Define a local temporary file\n",
        "temp_file = \"processed_data.jsonl\"\n",
        "\n",
        "# Clear file if it exists from a previous failed run (optional)\n",
        "if os.path.exists(temp_file):\n",
        "    os.remove(temp_file)\n",
        "\n",
        "for i in range(n_batches):\n",
        "    max_attempts = 3\n",
        "    for attempt in range(max_attempts):\n",
        "        try:\n",
        "            batch_df = df_subset_llm.iloc[i * batch_size : (i + 1) * batch_size].copy()\n",
        "            \n",
        "            # Process the batch\n",
        "            batch_df = get_llm_sentiment(batch_df, input_column, output_column, prompt_template)\n",
        "            batch_df = batch_df[[\"input_hash\", output_column]]\n",
        "            \n",
        "            # 2. Append to local JSONL file (Safe & Fast)\n",
        "            # mode='a' is append; orient='records' writes proper JSON lines\n",
        "            batch_df.to_json(temp_file, orient='records', lines=True, mode='a')\n",
        "            \n",
        "            print(f\"Saved batch {i+1}/{n_batches} locally.\")\n",
        "            break\n",
        "\n",
        "        except Exception as e:\n",
        "            if attempt + 1 >= max_attempts:\n",
        "                print(\"Failed to process batch\", i+1)\n",
        "            else:\n",
        "                print(f\"Attempt {attempt+1} failed for batch {i+1}/{n_batches}, sleeping for 10 seconds\")\n",
        "                print(f\"Error: {e}\")\n",
        "                time.sleep(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input_hash</th>\n",
              "      <th>llm_output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>93fed708cdd40a6d913f9f66c5a72d54c356d0aa16669d...</td>\n",
              "      <td>reasoning: the text is a purely factual descri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>949e9c240eb4e75485e6c19ba7628f244323ee3fc6a827...</td>\n",
              "      <td>reasoning: the text explicitly states the corp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c5b418da48cbefe7d4cca8a74eb87b28a0df20b504d913...</td>\n",
              "      <td>reasoning: the text explicitly mentions the co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b44b7a4f86a4130c03963f4b207253c15926fd45c7a86b...</td>\n",
              "      <td>reasoning: the text is a purely factual, descr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c758f909196698d45e8303d6795214c8fd43926caabc9f...</td>\n",
              "      <td>reasoning: the text is a purely factual descri...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          input_hash  \\\n",
              "0  93fed708cdd40a6d913f9f66c5a72d54c356d0aa16669d...   \n",
              "1  949e9c240eb4e75485e6c19ba7628f244323ee3fc6a827...   \n",
              "2  c5b418da48cbefe7d4cca8a74eb87b28a0df20b504d913...   \n",
              "3  b44b7a4f86a4130c03963f4b207253c15926fd45c7a86b...   \n",
              "4  c758f909196698d45e8303d6795214c8fd43926caabc9f...   \n",
              "\n",
              "                                          llm_output  \n",
              "0  reasoning: the text is a purely factual descri...  \n",
              "1  reasoning: the text explicitly states the corp...  \n",
              "2  reasoning: the text explicitly mentions the co...  \n",
              "3  reasoning: the text is a purely factual, descr...  \n",
              "4  reasoning: the text is a purely factual descri...  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "full_df = pd.read_json(temp_file, orient='records', lines=True)\n",
        "full_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split llm_output by '\\nscore' and clean the reasoning column\n",
        "import re\n",
        "def extract_reasoning_and_score(input_hash):\n",
        "    \"\"\"\n",
        "    Given an input_hash, find the corresponding llm_output in full_df,\n",
        "    and return a dictionary: {'reasoning': ..., 'score': ...}\n",
        "    \"\"\"\n",
        "    # Select the matching row\n",
        "    row = full_df.loc[full_df['input_hash'] == input_hash]\n",
        "    if row.empty:\n",
        "        return None\n",
        "\n",
        "    llm_output = row.iloc[0]['llm_output']\n",
        "    \n",
        "    # Split at the first occurrence of 'score:'\n",
        "    if '\\nscore:' not in llm_output:\n",
        "        print(ValueError(f\"No score found for input_hash: {input_hash}\"))\n",
        "        return None\n",
        "\n",
        "\n",
        "    split_llm = llm_output.split('\\nscore:')\n",
        "    reasoning, score = \"\".join(split_llm[0:-1]), split_llm[-1]\n",
        "\n",
        "\n",
        "    if 'reasoning' in llm_output:\n",
        "        reasoning = reasoning[len('reasoning:'):].strip()\n",
        "    elif len(reasoning) >= 0:\n",
        "        reasoning = reasoning.strip()\n",
        "    else:\n",
        "        print(\"reasoning\", reasoning)\n",
        "        raise ValueError(f\"No reasoning found for input_hash: {input_hash}\")\n",
        "    \n",
        "    score = score.replace('score:', '').strip()\n",
        "    return {\"reasoning\": reasoning, \"score\": score}\n",
        "\n",
        "# print(extract_reasoning_and_score(\"5e86b75638298802943dcc20093fae925be0c5146cbbf551a839cf47987d1e53\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29b59a8d504b45fdb3ae790686bc78d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying sentiment:   0%|          | 0/10313 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No score found for input_hash: 8e2fe9208bfb30f706a06ebc7accfc5bf03c227ae1f9d9101b1a4fcc35c43ef1\n",
            "No score found for input_hash: ba8aeb8f926c40f48e6cd31e8577057823a168d49e090be89602996b2926b653\n",
            "No score found for input_hash: a5695b34374a74e7267ec65ec97b35332857bcbe4e75c30988c40d9407a23fea\n",
            "No score found for input_hash: 5a2a4faac0f702b1a0688d3be867669a003a9037c965777cac6fc4b560bb181c\n",
            "No score found for input_hash: f98e409e42f5dc47579e44ed88fab7f89a1d825b077db7b56e00f654cec150e8\n",
            "No score found for input_hash: 25dafd9c79c017dafc37388a5565390113f2cb015f561198b12d457a4177d02a\n",
            "No score found for input_hash: ed8eb23dbb480732dff173b530f1a80101ce4fdc0e52fc6ba200ee1376c712d0\n",
            "No score found for input_hash: c604ad98101055267c01d240cab5f93524ca2067c851932b5e8f2e24a93f75fa\n",
            "No score found for input_hash: 7e592af8b7e182946522bcb00c7d1ba952b0fb25e00026b770fd2e462579b447\n",
            "No score found for input_hash: 2b445d8701a7bc24238cf51c3fee93a6063601e3debf4233245768b59469360c\n",
            "No score found for input_hash: d0918aa481812ee9cf1240acf85c7bed201233c0497da56747578caff68bacb0\n",
            "No score found for input_hash: f11aac5b9b533f34d3685efdad6658d38e8c411bea204504739dfd2fb4cd1aa2\n",
            "No score found for input_hash: b7db59ed8243609db3690c2874f6ab206b9cedbcfbd60ce0b231730162527dad\n",
            "No score found for input_hash: 89bddb7268eb36d43cbc828dec1e27a74a185d786a61d13950130fd9accd72ca\n",
            "No score found for input_hash: 32924e3a37bd6c656eb8cac6ff2ce823b75724ec15bb3d242071d1b6e10915f3\n",
            "No score found for input_hash: 33f9f03c3d78dc5481939113a6243ffe478046e290cb0cd1af88e3d668717a8e\n",
            "No score found for input_hash: fbd24e5e6c8c6538130e123b82f23a3f879c8e69ed3fd951599267582237ce67\n",
            "No score found for input_hash: db721386ede529a7cd5c15e2ecfa96e932a8ad62a56c920ce9c8f10665081b4d\n",
            "No score found for input_hash: 8b956fa443c80cc2c75fbfd9eb1a756136a439917a1829d8e037ddca2d384a3e\n",
            "No score found for input_hash: 027897634d10c49b00a06361aadcbc2ad81e66343bc976d5a58450ef308970f7\n",
            "No score found for input_hash: 1b779a6298ee2f4c983406717867f3e0a2b274043f22bcc2307fa03488805289\n",
            "No score found for input_hash: 67180b750fa70717529c07e98715db8040c7e9240c4ec7db1c52fe9f850bd8e9\n",
            "No score found for input_hash: 307b71c321d03d1405c780d88d0405c067d8af8a505a7a28a44213443b729c11\n",
            "No score found for input_hash: cba36931f09629b20f62c62cfbb4767a5ddd55d72f99c6cf66b7d5821b73ff99\n",
            "No score found for input_hash: 29e7a3c3dde73784b396e46bb940645aea1cbeeec4c274b80ab1222eccc74537\n",
            "No score found for input_hash: d22a51062ce9f2a8f36e7cb35b1bb72e9b9276dab1a42224dc704ee8f7338c8e\n",
            "No score found for input_hash: fc69d7916cd09330896ef15471b6f3db0186934103e3d60ea5a0285da2588896\n",
            "No score found for input_hash: 726b74ea2bb4ccf02e4f682b5b2ec1a00643c6331f260961f421975325074e15\n",
            "No score found for input_hash: 01c3c2565a8651112c8a95a842b4a4c287a2890b7efa6b28185ca8f5f75d12c4\n",
            "No score found for input_hash: 7e119e471e3ff381c105d08fe432c5508d9e480d45fa3c84a41cc22c5b971fc7\n",
            "No score found for input_hash: d8de139e4339b00adf2f1d8ed60d2809e7b74b59c033b5c971e6f92fe185b250\n",
            "No score found for input_hash: d34a9997939ed81de1ece5b36e3069d7311e67f6c0b5d49c1a0b99a39e5af4b1\n",
            "No score found for input_hash: 432b4b7b63c1a478eebdd772fcca4ebeccb4a22fc28bababa5aa1e372003af03\n",
            "No score found for input_hash: 938b956d4360dff0667d3d82aa06b5078fa5c19577a5fbc666b44751fc696891\n",
            "No score found for input_hash: d41698ae379f2be2e55ed4c14003101adb22da0322c6e7b410ce837f68b4dc77\n",
            "No score found for input_hash: 0dda8ad70736393006ab3f2e6d2fc2274dad9d91bca760418927d947d0bbe706\n",
            "No score found for input_hash: ac8e760b0639dd28250dbe7c55c01c2f3fbcdc02d6bab0db4e07732cc5f491a0\n",
            "No score found for input_hash: 2f9df954c6effa40e110d75860610a3091763b54534b6796f466eee911e92efe\n",
            "No score found for input_hash: 775c7bde79eec6f868d1f70c46468e3183ec315a47abbd789f98c0e7753aad8c\n",
            "No score found for input_hash: 48c033730dbf750470538d5cfe9a4d04da01725e5f265a78e59da14ddb502e77\n",
            "No score found for input_hash: 727b90b3264e334d6e8e399ea1a65e74f3cc35d4322f472159cd604ab830612e\n",
            "No score found for input_hash: 3c5541261ab5f34c341624743309911b3fc27bcec2bb1fb51db97b9e1198a314\n",
            "No score found for input_hash: ab8d05b0bdc44c126f5102a0c5fc6d85f0af6c46a7dc3b6b7a6f466c4896340b\n",
            "No score found for input_hash: 6fdf9c39c1c138e9aead0e1d3943af86569d58aea2752597088a73e470220338\n",
            "No score found for input_hash: b56144a872ef89732026cf661fdd4bcb58c84440fe9cc04b7e5575433eb595f4\n",
            "No score found for input_hash: d6f070fabdfd6d6136b72536405bb87bee79e77f1fcb9461b8a4d703fa0ed6c7\n",
            "No score found for input_hash: 891e212ed04483bed1b937bee9477966f5a5e028f03f933b7a0b9a0914ed2e1b\n",
            "No score found for input_hash: 1591d2ace22d02c1bdfdcf54a15216f3a34c62b7ba8535b8ef18e2f31f5f4aa2\n",
            "No score found for input_hash: c298b64fa27230ac1ce3864a891ba67f7cd422a64b07b0746242e05554f72da7\n",
            "No score found for input_hash: 0d0ed71edc5a50a68d5ba56010f83e573059b8b363e80796ecd6d85cf082d95d\n",
            "No score found for input_hash: 5527b4b5570c8e1fa7b6a2f22af3991ac7f1c948863aed864a183b8ccba371aa\n",
            "No score found for input_hash: 6f5c9f85720421f73f7c6f9a1072e8c9e9cd8b9e506d07c4bfaaa0af9741f51e\n",
            "No score found for input_hash: b8eab9603df01f3a2a625aaf2d4575254112e83d8705c8370fcc30e3e04ff4d4\n",
            "No score found for input_hash: 7c38823e76b25a36e428b31c66dfcb2f5a40eba61e7073c8e7890db38ed29d80\n",
            "No score found for input_hash: 0cf294cd4b11da31ec584fcea451e9bbf7484b1f3028ff16656aaa218b220b9d\n",
            "No score found for input_hash: a021a5d1bdcac05e768a908ba8cf5af7c6f8b332925cd1959c7fa7799c9fa6d2\n",
            "No score found for input_hash: 8bde66ae97017367d380ee15c242414c4cdfddf85b87ab09d4029aee3784ebc7\n",
            "No score found for input_hash: 5567d0d1b4e0a0d0a0b605d56190ddcb8957b0cca28df6c4cd71104c2fa158e6\n",
            "No score found for input_hash: 3026b94ba0bd6da18c1147a57213ef728022f6f2c87fae1f41c6a4696abb4278\n",
            "No score found for input_hash: 4d4f454c35b266abfa5c8927e0f3960b85f67deaf2b11b8fbac5c555942764f2\n",
            "No score found for input_hash: 0746f7ac95cd31719f211420163b93da608765a363d156f1f807b4c9c5389f98\n",
            "No score found for input_hash: 75513ab83f6af1bab30794236c2378dd8669a35579c1701d65a1c1b6a5d4b0d0\n",
            "No score found for input_hash: f69d5674b21741d3e3e3076950643150b10e6a6e395ea3b953150399fa49f5c2\n",
            "No score found for input_hash: 3cf81bc65bb20ae8a1a25711eac2b0dcb30f8639269a3257508a88adedb218b1\n",
            "No score found for input_hash: de4da6d6425cfd1c1d9ecea709a2e52cd2b2e42b5abe693cb7710bab4e34e480\n",
            "No score found for input_hash: 74212e7aeea7e0905593bfc368c0bbb53928fc2c45b40e61f7ddf04a72c33644\n",
            "No score found for input_hash: f9db04b6daf9526713dc08d9fbb2227c196d28b763150ad69d2333f2a4fa1cd2\n",
            "No score found for input_hash: dbdd8d14753165b9076f4bc7ad4ce3715da662da7330cbc90b42c281ae262760\n",
            "No score found for input_hash: 48b135af44fd72760111b7332b7b2c363c0245cb480e128915a9264330496d40\n",
            "No score found for input_hash: 13dfbf0e0b2c247d12841455ad1e44c9d0d95f844603a2fd6ac06cefcc445c30\n",
            "No score found for input_hash: 58e5e7ebb8e0eb89619d70445ea0d6b1c4bc7fa79a2a5af57a6944c5aecb8df8\n",
            "No score found for input_hash: 4203a129f1a31f5bdda09cd69a4553ef1a7b4fad9c9554395b5287dde9abba63\n",
            "No score found for input_hash: c5dc127fd25fca89b3335d0c4a1a3a5b11787fa5678856776bb7b3486aabbbe7\n",
            "No score found for input_hash: 0921f9acbc82f596b471c9f50e56eb5f325553fed84ae0d16c9d81b15e2f1a75\n",
            "No score found for input_hash: 1778802a73200bc1e8a9c627d33176eedd5c613c9fd749c38d74c9a748edc6dd\n",
            "No score found for input_hash: 357f1ef4c9cdea0c73979116509543c033c74c50e491b320da8af8adb460ea01\n",
            "No score found for input_hash: dfbfc180b074a56b0e0fd818bbfdbae9b846dfe2e522a5338a72e2d30e37677b\n",
            "No score found for input_hash: 64079cc162cc12ab55ca0c9ede9d0c5c67e2ae437f41af2e7a06ce2b1fe0166c\n",
            "No score found for input_hash: 96499f63fd6d4a474dd94e7f069e5b283c3c7bd83943e9af73f6851baaeab5f9\n",
            "No score found for input_hash: 25b3b4f1b9bf33e69425351fa498da30bf7035aea3a6c4efa026a03bed549493\n",
            "No score found for input_hash: de095e28bc91fc55e8374a4356584e2e48f51c3abcf94db71401c16dbd82c26b\n",
            "No score found for input_hash: dd8ed7b45824981cccb1ff2bb9545688025c0e865d3d6dc7cfab5c69f80239dd\n",
            "No score found for input_hash: 06c9376de62ec7b10a8ef8856444b1ee107e2756c901d2efeccfffff77a8af7b\n",
            "No score found for input_hash: a8339e01c93d9b19a85b0f85b8d674425985bc2bc6d2b2cee9742dc069a020f8\n",
            "No score found for input_hash: dc997aaa9428d11a66b8de4c8ef1efd2f3722966822f50bc591a46fd9c7206af\n",
            "No score found for input_hash: 9685d473bc714f81013f2d4b63c728af45fd86b4785fb92a76b506f71da7b26b\n",
            "No score found for input_hash: 931e4c0ba7e80a0d8a31f96a1002c23d9b3b24f411b093cebdc654c19cf8ab84\n",
            "No score found for input_hash: 5ee6829796ff2c5f41cbda3f2a3ea71593262329bf12a1eb4cc3d262cd35deca\n",
            "No score found for input_hash: 24338337296abaac831b30bef0b56765960f1f6c79ee2cffe1364fe62e64c034\n",
            "No score found for input_hash: 0d97f25c7f24a2cca2b897030a892b1be98e68b3305335e914b50ecaa191ebd3\n",
            "No score found for input_hash: 345e3e4e28b6c9fb3f38e0d26aa95dcf6ae9b7122921a670412409eb42c79916\n",
            "No score found for input_hash: 5d1cf4db0e0f453923cab003e692d572d083e0ea6b762b89ed4b8a10aa2458d7\n",
            "No score found for input_hash: f8620aeed6d6f241c9905e497e8035152f080e2f4160c48fcc3cfed72f1cf3b9\n",
            "No score found for input_hash: 2438222f52d7129b49eb8bb1b09152ce56b432f50cc68b82d74eed18194b8088\n",
            "No score found for input_hash: 87d96d5ef9f9efa244a88d6b7adcf58077b59cdfb27678ede6882385157d7719\n",
            "No score found for input_hash: 5b49cc1992d1c70594392924bec862f03c6d7165b3de2d7f14b69601d356eb04\n",
            "No score found for input_hash: 335fd7bd1faa84b2d3d20e3c0e54ae0d06d43c91713cecd53ecb968ed4231308\n",
            "No score found for input_hash: 396bedc61d9ff6916e1bdbf3fcb7a6e7c88ac1fe36a2162d23222332a535d495\n",
            "No score found for input_hash: 5d6bb92851e2b78cbc37d4cbb1149a26cb5808158c02ddb7b65d9f2e9975166b\n",
            "No score found for input_hash: b08af44ab41c918b623dfd1d7518de515f5a473f3999742829be056483b0ec05\n",
            "No score found for input_hash: b6a8419e1079a24ecd7fe01d677b473b080d6ce113b1d3bca682dc19dfee8694\n",
            "No score found for input_hash: f013f9f049296a991ed2ef8d49e7de654cb01dd75b99beb52e3f1798769bc4ac\n",
            "No score found for input_hash: cb660ff013d1c51f2309ca68fc0cd33c9c19efba239240aac16e115938a8c435\n",
            "No score found for input_hash: 4c24556105360dbd5ec234bf12fd4e2410caa0ef23df9ae7b93cf879499cda99\n",
            "No score found for input_hash: 7056beabbe90975c1e1feb314e6549343fb10c99b0c5f84005c011df6020e5ec\n",
            "No score found for input_hash: af8ad95554e63d0db541a6a5bbd54074780cfb6528f91a51aa28d92ca9f214eb\n",
            "No score found for input_hash: 5351d27f86d1fee16e2cd11368fce2896446db8967bbe798f0ecf987209404d9\n",
            "No score found for input_hash: 267f6b602ec95be7f2fc23e1c143a24f1600b194cbe2b800c7662b7ccf0d00f4\n",
            "No score found for input_hash: 83125065b24856b8afb1834e71fcb9c9baa6c5fd656989ef21b15783692b73a0\n",
            "No score found for input_hash: 5d1717e16f0eb6e198fbaa00c49e7f11101a59d2e5350570243663ccbe88a39d\n",
            "No score found for input_hash: 7586e9d1380b2850311c33d4beea0b99a85132bfed67989c04f677a608a1bda4\n",
            "No score found for input_hash: c162568d48ebffc473b1c724404de831e34e843ae28fd79ff5f722522343c9f8\n",
            "No score found for input_hash: 5452a330724b29cde791061d632f1aa8b405e5139df6d0c6806cf408b69c9908\n",
            "No score found for input_hash: 19bfe82e9961804d13c2f6be887875ef641bfc6d7a787ac55b2f8833f5202a37\n",
            "No score found for input_hash: 49c516f7849ce79e1b6c8be21aa30b95640e3602f7adde63f1581b5fa9aead75\n",
            "No score found for input_hash: 74034813ac3a10229693aaed61ef2ad3bdd01835ba477d79af6eb3808d39162b\n",
            "No score found for input_hash: 3d8ec0448b50aa5eabbeca90d7957c4eb9f885a04cbf226bb6cbccf7be9f7828\n",
            "No score found for input_hash: deb2679a9cc4101190b70b958feddd9cad5e3da7964ab2bfaf60cf0fa4194380\n",
            "No score found for input_hash: 59a9be00ef50462bbe928bf483453c928b1e4753f60c41ab38a7040a3e173cd0\n",
            "No score found for input_hash: 33c9a89d291f1eaf5dc8071a7e979e6cd3b8485792caee6804b142b09f25e555\n",
            "No score found for input_hash: 901ab9337294c6893ee12d14de640a3e504b782720bc75f5852a630a4bae9d2a\n",
            "No score found for input_hash: f0be095da30cde5235dc591445b9fe03b2693b4d098a14487775db9783b6b39d\n",
            "No score found for input_hash: 96c95867151aff577d0398e140a95989c637529f37c9c21827577ad6377265b9\n",
            "No score found for input_hash: baf7dd72230ddc447f53ffa169be77ecf468819eb5e4f728e0abb42867bc3fd9\n",
            "No score found for input_hash: 9331fe64c7b832470f385a1a25359a007f8504f8cd38421d63e20becb8d05898\n",
            "No score found for input_hash: 38a6cb2e0b4b82bb1c1c94a3522cdbbb763667cf33a85762c7adc2f3b35da649\n",
            "No score found for input_hash: 2106ba2bf4a2c080ccfb992c42e80ec86cf88831ab5455cc82c96a7dca319db6\n",
            "No score found for input_hash: b567bc2f5b174bb0d2776755e926bf380aef4f2269b4955e34a75b5c2560e6c5\n",
            "No score found for input_hash: 675b7fcc1a3b86529fec8a94179a2a8392345a6f0964e8704411a70a6a58241b\n",
            "No score found for input_hash: 4beebed93315a8979cb7149717da58b0ab975d445b5ad56ed65e3bce62b34c8f\n",
            "No score found for input_hash: bc74d80bd96e4e292f77347342444d3f014191c81e909b23ecef8f57fa29eb4f\n",
            "No score found for input_hash: 04cbcfe924df1d09b52234215e3729608613c9712ced38cc2d2128e45d38164e\n",
            "No score found for input_hash: fad89328617caa1c68fcbd602829e29f23cdf260624c4c52c9d4b193b1b59abf\n",
            "No score found for input_hash: 54bdfdf87a5720494f4554439605bae5eafceed43c24a0b12a0ba030cbe1a528\n",
            "No score found for input_hash: d4633b4416b1869a2d25d3d76474f828dcd24224b7e32c7d2d8566c731a15b9f\n",
            "No score found for input_hash: 5b1aaf8b935f9b76e4aadcc090f32c2a282579ecb40aa5011fbba58e4c740a28\n",
            "No score found for input_hash: be5e3dfa61a42b75be4a4ad74480f20039dbde739559a011bf2526f0e5dbd245\n",
            "No score found for input_hash: 697e07441e231ebad06bdd049fe6f52ec22413ebac89b02a3b338e1a221e88d5\n",
            "No score found for input_hash: 8276a39e57f36f561dc298be83915a2f329b62a35626e8a416b5bb988d14bfb8\n",
            "No score found for input_hash: c2ab81c7cfccbad3b169b1128bc1593408b8b0b68529c9cefee46c293ff0b916\n",
            "No score found for input_hash: 3e0f5453e042780216d7b9fa659a4fc97cbf27af12749f1e9736b471233b4d67\n",
            "No score found for input_hash: fed0e2675f3328ca04bf87753af16faaa97841fc278e90af6fc0f2c76a4f9d2d\n",
            "No score found for input_hash: ca2fb50e998674e44784df7313396830baba0670e54c3b5b1227bae1468d0108\n",
            "No score found for input_hash: 79bc53002ba093e5fd204fb9deb1048ecbef867bc8d153fba0482c518a957142\n",
            "No score found for input_hash: 1c1d138f576d367109d30d7fc68f30f597997100772fd90450b45bcea677f312\n",
            "No score found for input_hash: ecc31c70a7e3dc050363769a959afa04fd61f52a4dca4fcb521c223f093b2be5\n",
            "No score found for input_hash: 2947bdd5f75571758acc182f5fcce6af457c56739abec03b2383d1ad4ea0d81a\n",
            "No score found for input_hash: 07173b5ed7fcd4ef5b75b88ae2f99c84fba4c4f43539c7f51f9071191aee6b88\n",
            "No score found for input_hash: 0503799cb194f4f1bb78db1845d08de8b041b3cdeff96dbcac9034a563bfc4fe\n",
            "No score found for input_hash: 3b3a93b308fc37ee95b543a759439785c07c9e9992f2ee5a163c074fd25d9438\n",
            "No score found for input_hash: 830adf986e10f8c5c60825e5145be5b35787299cb86ca0f707fadf5de73765d2\n",
            "No score found for input_hash: de0aad566d2b7ff66fecbee1ccf80856015965aea228c99ec9a3c1fbc22886f9\n",
            "No score found for input_hash: 7d9fbd6bc84174a33628e74a7193130b19c0a03751c69431328fb3a801476f83\n",
            "No score found for input_hash: 310c912dea3732ec878bceda4c2a464755acad9d7f0289ee786b566ad6b61cca\n",
            "No score found for input_hash: 01d5450cb0c1836ff25a80734e91cc0a44dd926c3adc61afa5ef901b9ede1596\n",
            "No score found for input_hash: 2cf6900bdf8d7b82825aa70ffa73d6282a220be40cbc237b3ac0a508ad737d84\n",
            "No score found for input_hash: 27600f3774018bbe6ec62bb65e325dd22ad8725f7da8c5e6e869a476d934bdab\n",
            "No score found for input_hash: ca271cc741d6e8ced5a2608592d7b6d90d7389729a960526fbc217f4ae6f3e9b\n",
            "No score found for input_hash: bdbe6443ca1205272dbabaa70c7e52e62655a2f73a5f98ed06dccce1085f233f\n",
            "No score found for input_hash: a6e87b2148c4f021073805e2d3bdf7cee94dc743d1fcadda323cf07bc5e3e71b\n",
            "No score found for input_hash: 81bc0734342be972b00bb33e1bb88dc380e3cfc491737a750e6435ddb3e4ac2f\n",
            "No score found for input_hash: 2d1679c099eaee441715f2e09353c3b52cd4db38ca3713fbf12110ed6224a368\n",
            "No score found for input_hash: da450d6d30d475be5ff5af5f5fb72a103ac77f2af343d99d8882215ee3ce0b82\n",
            "No score found for input_hash: fe5c3f75b9c8046ae9c5e9c0a979758b417a050c1647b99b2f648923d464912f\n",
            "No score found for input_hash: 843b3971ff86a84392df46d7687ab3f0c28474a6af6ed13b2a3a4bbd97447ced\n",
            "No score found for input_hash: 2c84fa5317174777c2c75acb23e4d29b00caf3abb1f0aab0d390e5f979767230\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input_hash</th>\n",
              "      <th>input</th>\n",
              "      <th>summary</th>\n",
              "      <th>model</th>\n",
              "      <th>llm_sentiment_class</th>\n",
              "      <th>llm_sentiment_model</th>\n",
              "      <th>llm_sentiment_rationale</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5e86b75638298802943dcc20093fae925be0c5146cbbf5...</td>\n",
              "      <td>FINANCIAL STATEMENTS AND SUPPLEMENTARY DATA IN...</td>\n",
              "      <td>Here's a summary of the financial statement:\\n...</td>\n",
              "      <td>Claude</td>\n",
              "      <td>-1</td>\n",
              "      <td>DeepSeek-V3.2</td>\n",
              "      <td>the text explicitly states the company is \"ope...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>c5b4129b8c9c94491f949c87ac452f30af0f11b8a68e5d...</td>\n",
              "      <td>FINANCIAL STATEMENTS AND SUPPLEMENTARY DATA.  ...</td>\n",
              "      <td>Based on the provided excerpt, here's a summar...</td>\n",
              "      <td>Claude</td>\n",
              "      <td>-2</td>\n",
              "      <td>DeepSeek-V3.2</td>\n",
              "      <td>the text explicitly describes \"ongoing financi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a488c022380bcf59d4d3c99127ed2554fa67f86854119e...</td>\n",
              "      <td>. Report of Independent Registered Public Acco...</td>\n",
              "      <td>This appears to be a partial financial stateme...</td>\n",
              "      <td>Claude</td>\n",
              "      <td>0</td>\n",
              "      <td>DeepSeek-V3.2</td>\n",
              "      <td>the text is purely descriptive of accounting p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>52db0b9f1bfe2db5807d09128d511e2176c0226e0558c7...</td>\n",
              "      <td>Index to Consolidated Financial Statements All...</td>\n",
              "      <td>This appears to be a partial financial stateme...</td>\n",
              "      <td>Claude</td>\n",
              "      <td>0</td>\n",
              "      <td>DeepSeek-V3.2</td>\n",
              "      <td>the text is a purely factual description of ac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a5d562bb3069324a9facf4ecb6fdf52aee051460a2cecf...</td>\n",
              "      <td>.  ACCOUNTING FIRM To the Board of Directors a...</td>\n",
              "      <td>Here's a summary of the financial statement:\\n...</td>\n",
              "      <td>Claude</td>\n",
              "      <td>0</td>\n",
              "      <td>DeepSeek-V3.2</td>\n",
              "      <td>the text is a purely factual, neutral descript...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          input_hash  \\\n",
              "0  5e86b75638298802943dcc20093fae925be0c5146cbbf5...   \n",
              "1  c5b4129b8c9c94491f949c87ac452f30af0f11b8a68e5d...   \n",
              "2  a488c022380bcf59d4d3c99127ed2554fa67f86854119e...   \n",
              "3  52db0b9f1bfe2db5807d09128d511e2176c0226e0558c7...   \n",
              "4  a5d562bb3069324a9facf4ecb6fdf52aee051460a2cecf...   \n",
              "\n",
              "                                               input  \\\n",
              "0  FINANCIAL STATEMENTS AND SUPPLEMENTARY DATA IN...   \n",
              "1  FINANCIAL STATEMENTS AND SUPPLEMENTARY DATA.  ...   \n",
              "2  . Report of Independent Registered Public Acco...   \n",
              "3  Index to Consolidated Financial Statements All...   \n",
              "4  .  ACCOUNTING FIRM To the Board of Directors a...   \n",
              "\n",
              "                                             summary   model  \\\n",
              "0  Here's a summary of the financial statement:\\n...  Claude   \n",
              "1  Based on the provided excerpt, here's a summar...  Claude   \n",
              "2  This appears to be a partial financial stateme...  Claude   \n",
              "3  This appears to be a partial financial stateme...  Claude   \n",
              "4  Here's a summary of the financial statement:\\n...  Claude   \n",
              "\n",
              "  llm_sentiment_class llm_sentiment_model  \\\n",
              "0                  -1       DeepSeek-V3.2   \n",
              "1                  -2       DeepSeek-V3.2   \n",
              "2                   0       DeepSeek-V3.2   \n",
              "3                   0       DeepSeek-V3.2   \n",
              "4                   0       DeepSeek-V3.2   \n",
              "\n",
              "                             llm_sentiment_rationale  \n",
              "0  the text explicitly states the company is \"ope...  \n",
              "1  the text explicitly describes \"ongoing financi...  \n",
              "2  the text is purely descriptive of accounting p...  \n",
              "3  the text is a purely factual description of ac...  \n",
              "4  the text is a purely factual, neutral descript...  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Enrich df_refined with llm_sentiment_class and llm_sentiment_rationale using extract_reasoning_and_score\n",
        "\n",
        "def classify_sentiment(row, model_name = \"DeepSeek-V3.2\"):\n",
        "    if row['llm_sentiment_class'] is not None:\n",
        "        return pd.Series({\n",
        "            \"llm_sentiment_class\": row['llm_sentiment_class'], \n",
        "            \"llm_sentiment_rationale\": row['llm_sentiment_rationale'],\n",
        "            \"llm_sentiment_model\": model_name\n",
        "        })\n",
        "\n",
        "    extraction = extract_reasoning_and_score(row['input_hash'])\n",
        "    if extraction is None:\n",
        "        return pd.Series({\"llm_sentiment_class\": None, \"llm_sentiment_rationale\": None})\n",
        "    # Convert score to class string (convention: -1=negative, 0=neutral, 1=positive)\n",
        "    return pd.Series({\n",
        "        \"llm_sentiment_class\": extraction[\"score\"],\n",
        "        \"llm_sentiment_rationale\": extraction[\"reasoning\"],\n",
        "        \"llm_sentiment_model\": model_name\n",
        "    })\n",
        "\n",
        "# Apply classification with tqdm progress bar\n",
        "results = []\n",
        "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Classifying sentiment\"):\n",
        "    results.append(classify_sentiment(row))\n",
        "result_df = pd.DataFrame(results, index=df.index)\n",
        "df[[\"llm_sentiment_class\", \"llm_sentiment_rationale\", \"llm_sentiment_model\"]] = result_df\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Save Generated Dataset in Hugging face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2351e19d4d29473ea0c943e99fa3ae44",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/2 [00:00<?, ? shards/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6239145b7e804758a3a5f7dda3d7a388",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/4 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dedb1a03d5874c15bd7d9ce62514a619",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ba8000321fa465c9b98f369ec6be6cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "New Data Upload: |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10a88869067c4a0a98eebc46b8d9bd12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/4 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15e96d92fb43440fa18ac4bba35f6e54",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7cafe35a0894404c84c727badeae3d05",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "New Data Upload: |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/datasets/ArthurMrv/EDGAR-CORPUS-Financial-Summarization-Labeled/commit/8ba7ba69157e714265f063c15a88d69342f23122', commit_message='Upload dataset', commit_description='', oid='8ba7ba69157e714265f063c15a88d69342f23122', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/ArthurMrv/EDGAR-CORPUS-Financial-Summarization-Labeled', endpoint='https://huggingface.co', repo_type='dataset', repo_id='ArthurMrv/EDGAR-CORPUS-Financial-Summarization-Labeled'), pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "# Prepare the Dataset from df_refined\n",
        "hf_dataset = Dataset.from_pandas(df, preserve_index=False)\n",
        "\n",
        "hf_dataset.push_to_hub(DATASET_NAME, split=\"refined\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
