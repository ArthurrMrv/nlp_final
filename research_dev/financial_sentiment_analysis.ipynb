{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Financial News Sentiment Analysis\n",
        "\n",
        "This notebook performs sentiment classification (bullish, neutral, bearish) on financial news using:\n",
        "1. GMI API (DeepSeek-V3.2) as baseline\n",
        "2. Two pre-trained transformer models for comparison\n",
        "3. Fine-tuning the best model\n",
        "4. Re-evaluation after fine-tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install datasets transformers torch requests pandas scikit-learn tqdm -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
        "\n",
        "DATASET_NAME = \"ArthurMrv/EDGAR-CORPUS-Financial-Summarization-Labeled\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TRAIN_SPLIT = 0.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Successfully logged in to Hugging Face Hub!\n"
          ]
        }
      ],
      "source": [
        "# Authenticate with Hugging Face Hub\n",
        "from huggingface_hub import login\n",
        "import getpass\n",
        "\n",
        "login(token=HF_TOKEN)\n",
        "\n",
        "print(\"\\nSuccessfully logged in to Hugging Face Hub!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-aa04a8bc-03dd-4947-ae68-e1906ef13ff2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>summary</th>\n",
              "      <th>model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FINANCIAL STATEMENTS AND SUPPLEMENTARY DATA IN...</td>\n",
              "      <td>Here's a summary of the financial statement:\\n...</td>\n",
              "      <td>Claude</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FINANCIAL STATEMENTS AND SUPPLEMENTARY DATA.  ...</td>\n",
              "      <td>Based on the provided excerpt, here's a summar...</td>\n",
              "      <td>Claude</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>. Report of Independent Registered Public Acco...</td>\n",
              "      <td>This appears to be a partial financial stateme...</td>\n",
              "      <td>Claude</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Index to Consolidated Financial Statements All...</td>\n",
              "      <td>This appears to be a partial financial stateme...</td>\n",
              "      <td>Claude</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>.  ACCOUNTING FIRM To the Board of Directors a...</td>\n",
              "      <td>Here's a summary of the financial statement:\\n...</td>\n",
              "      <td>Claude</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa04a8bc-03dd-4947-ae68-e1906ef13ff2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aa04a8bc-03dd-4947-ae68-e1906ef13ff2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aa04a8bc-03dd-4947-ae68-e1906ef13ff2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               input  \\\n",
              "0  FINANCIAL STATEMENTS AND SUPPLEMENTARY DATA IN...   \n",
              "1  FINANCIAL STATEMENTS AND SUPPLEMENTARY DATA.  ...   \n",
              "2  . Report of Independent Registered Public Acco...   \n",
              "3  Index to Consolidated Financial Statements All...   \n",
              "4  .  ACCOUNTING FIRM To the Board of Directors a...   \n",
              "\n",
              "                                             summary   model  \n",
              "0  Here's a summary of the financial statement:\\n...  Claude  \n",
              "1  Based on the provided excerpt, here's a summar...  Claude  \n",
              "2  This appears to be a partial financial stateme...  Claude  \n",
              "3  This appears to be a partial financial stateme...  Claude  \n",
              "4  Here's a summary of the financial statement:\\n...  Claude  "
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Load in streaming mode\n",
        "ds = load_dataset(DATASET_NAME)\n",
        "\n",
        "df = ds.to_pandas()\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Setup API for Classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from huggingface_hub import InferenceClient\n",
        "\n",
        "client = InferenceClient(\n",
        "    api_key=HF_TOKEN,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "def request_sentiment(text, prompt_template):\n",
        "    prompt = prompt_template.format(input_text=text)\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"deepseek-ai/DeepSeek-V3.2\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "    )\n",
        "    response = completion.choices[0].message\n",
        "    # Extract the word (expected to be only the class label)\n",
        "    return response.content.strip().lower()\n",
        "\n",
        "def get_llm_sentiment(df, input_column, output_column, prompt_template):\n",
        "    \"\"\"\n",
        "    Given a DataFrame, input column, and output column name,\n",
        "    calls the DeepSeek LLM via Hugging Face Inference API to get the sentiment for each row.\n",
        "    The result will be stored in a new column (output_column).\n",
        "    \"\"\"\n",
        "\n",
        "    tqdm.pandas(desc=\"Classifying sentiment\")\n",
        "    df[output_column] = df[input_column].progress_apply(lambda x: request_sentiment(x, prompt_template))\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt_template = \"\"\"\n",
        "You are a Financial News Sentiment Classifier.\n",
        "Your task is to classify the sentiment EXPLICITLY expressed in the text regarding stocks.\n",
        "\n",
        "### Scoring Rubric:\n",
        "+2 (Highly Bullish): Text explicitly states prices are soaring, skyrocketing, or reports massive success/breakthroughs.\n",
        "+1 (Bullish): Text describes price increases, positive outlooks, or favorable conditions.\n",
        " 0 (Neutral): Text is purely factual with no emotional charge, or describes flat price movement.\n",
        "-1 (Bearish): Text describes price drops, fears, negative outlooks, or unfavorable conditions.\n",
        "-2 (Highly Bearish): Text explicitly states prices are crashing, plummeting, or reports crisis/panic.\n",
        "\n",
        "### Critical Rules:\n",
        "1. **React to the text, not the market.** If the text says \"stocks are down,\" the score MUST be negative, even if the reason is generic (like the FED).\n",
        "2. Do not assume news is \"priced in.\" Analyze the immediate emotional and factual content of the snippet.\n",
        "3. Ignore external context. Only use the provided text.\n",
        "\n",
        "### Output Format:\n",
        "Reasoning: [1 sentence identifying the specific keywords or claims in the text that justify the score]\n",
        "Score: [Integer between -2 and 2]\n",
        "\n",
        "---\n",
        "Article: {input_text}\n",
        "\"\"\"\n",
        "input_column = \"text\"\n",
        "output_column = \"llm_response\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'reasoning: the text explicitly describes a company \"operating at a loss with a working capital deficit,\" notes \"substantial concerns about the company\\'s ability to continue operations,\" and lists multiple \"financial challenges and operational risks,\" which are all explicitly unfavorable conditions.  \\nscore: -1'"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_txt = \"\"\"\n",
        "Here's a summary of the financial statement: Financial Health Overview: - The company (Digerati) is operating at a loss with a working capital deficit - There are substantial concerns about the company's ability to continue operations - Management has addressed these concerns in Note 2 Revenue Streams: 1. Global VoIP Services - Provides VoIP services to U.S. and foreign telecommunications companies - Focuses on markets in Mexico, Asia, the Middle East, and Latin America 2. Cloud Communication Services - Offers hosted IP/PBX services to resellers and enterprise customers - Includes various features like call center applications, prepaid services, and customized IP/PBX features Key Expenses: - Transmission and termination charges from suppliers - Infrastructure and network costs - Internet bandwidth charges - Licensing and co-location charges - Installation costs Financial Risk Factors: - Credit risk from trade receivables - Potential exposure from bank deposits exceeding federally insured limits - Customer concentration risk (four customers comprise 20% of revenue) Revenue Recognition: - Based on evidence of arrangement, service delivery, fixed pricing, and collectability - Company acts as primary obligor with pricing authority and credit risk responsibility This statement indicates a company with established revenue streams but facing significant financial challenges and operational risks.\"\"\"\n",
        "request_sentiment(input_txt, prompt_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Classifying sentiment: 100%|██████████| 10/10 [00:31<00:00,  3.18s/it]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bd019921-a71c-4790-80db-ff62ad5a5117\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "      <th>extra_fields</th>\n",
              "      <th>llm_response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-01-01T00:00:00Z</td>\n",
              "      <td>New Ted Cruz Super PAC with $4M ad buy\\n\\n(CNN...</td>\n",
              "      <td>{\"publication\":\"CNN\",\"author\":\"Theodore Schlei...</td>\n",
              "      <td>reasoning: the text is about political campaig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-01-01T00:00:00Z</td>\n",
              "      <td>Write an essay, win a 100-year-old movie theat...</td>\n",
              "      <td>{\"publication\":\"CNN\",\"author\":\"Kevin Conlon\",\"...</td>\n",
              "      <td>reasoning: the article discusses an essay cont...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-01-01T00:00:00Z</td>\n",
              "      <td>Putin points to NATO threat in new security st...</td>\n",
              "      <td>{\"publication\":\"CNN\",\"author\":\"Euan McKirdy\",\"...</td>\n",
              "      <td>reasoning: the text is a factual report on geo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-01-01T00:00:00Z</td>\n",
              "      <td>Better results offset costs of prostate surger...</td>\n",
              "      <td>{\"publication\":\"Reuters\",\"author\":\"Lisa Rapapo...</td>\n",
              "      <td>reasoning: the article discusses potential cos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-01-01T00:00:00Z</td>\n",
              "      <td>Cruz super-PACs unveil Iowa TV ad buy | TheHil...</td>\n",
              "      <td>{\"publication\":\"The Hill\",\"author\":\"Jesse Byrn...</td>\n",
              "      <td>reasoning: the text describes an \"uptick in sp...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd019921-a71c-4790-80db-ff62ad5a5117')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bd019921-a71c-4790-80db-ff62ad5a5117 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bd019921-a71c-4790-80db-ff62ad5a5117');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                   date                                               text  \\\n",
              "0  2016-01-01T00:00:00Z  New Ted Cruz Super PAC with $4M ad buy\\n\\n(CNN...   \n",
              "1  2016-01-01T00:00:00Z  Write an essay, win a 100-year-old movie theat...   \n",
              "2  2016-01-01T00:00:00Z  Putin points to NATO threat in new security st...   \n",
              "3  2016-01-01T00:00:00Z  Better results offset costs of prostate surger...   \n",
              "4  2016-01-01T00:00:00Z  Cruz super-PACs unveil Iowa TV ad buy | TheHil...   \n",
              "\n",
              "                                        extra_fields  \\\n",
              "0  {\"publication\":\"CNN\",\"author\":\"Theodore Schlei...   \n",
              "1  {\"publication\":\"CNN\",\"author\":\"Kevin Conlon\",\"...   \n",
              "2  {\"publication\":\"CNN\",\"author\":\"Euan McKirdy\",\"...   \n",
              "3  {\"publication\":\"Reuters\",\"author\":\"Lisa Rapapo...   \n",
              "4  {\"publication\":\"The Hill\",\"author\":\"Jesse Byrn...   \n",
              "\n",
              "                                        llm_response  \n",
              "0  reasoning: the text is about political campaig...  \n",
              "1  reasoning: the article discusses an essay cont...  \n",
              "2  reasoning: the text is a factual report on geo...  \n",
              "3  reasoning: the article discusses potential cos...  \n",
              "4  reasoning: the text describes an \"uptick in sp...  "
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_labeled = get_llm_sentiment(df, input_column, output_column, prompt_template)\n",
        "df_labeled.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>llm_response</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>reasoning: the text is about political campaign funding and advertisements, with no mention of stock prices, market conditions, or any financial sentiment relevant to stocks.  \\nscore: 0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reasoning: the article discusses an essay contest to win a historic movie theater, focusing on the contest details and the business's potential, with no mention of stocks, stock prices, or market sentiment.  \\nscore: 0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reasoning: the text is a factual report on geopolitical developments and security strategy without any explicit mention of stock prices, market movements, or financial sentiment.  \\nscore: 0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reasoning: the article discusses potential cost savings and better outcomes from prostate surgery at specialized centers, which is a positive outlook on medical outcomes but does not mention stock prices, market conditions, or investment sentiment.  \\nscore: 0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reasoning: the text describes an \"uptick in spending,\" \"nearly $20 million\" raised, and the candidate being \"in a strong position,\" which indicates favorable conditions and a positive outlook.  \\nscore: 1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reasoning: the text is a purely factual report on military air strikes with no mention of any stocks, financial markets, prices, or economic conditions.\\nscore: 0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reasoning: the text reports a factual military procurement decision without any explicit claims about stock price movement, outlook, or financial performance for the involved companies.  \\nscore: 0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reasoning: the text reports on a prison fight in guatemala with no mention of stocks, markets, prices, or any financial sentiment whatsoever.  \\nscore: 0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reasoning: the text discusses donald trump's political aspirations and a new year's call, with no mention of stocks, market prices, outlooks, or financial conditions.\\nscore: 0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reasoning: the article discusses geopolitical conflict and violence with no mention of financial markets, stock prices, or economic conditions related to stocks.  \\nscore: 0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "llm_response\n",
              "reasoning: the text is about political campaign funding and advertisements, with no mention of stock prices, market conditions, or any financial sentiment relevant to stocks.  \\nscore: 0                                                                              1\n",
              "reasoning: the article discusses an essay contest to win a historic movie theater, focusing on the contest details and the business's potential, with no mention of stocks, stock prices, or market sentiment.  \\nscore: 0                                              1\n",
              "reasoning: the text is a factual report on geopolitical developments and security strategy without any explicit mention of stock prices, market movements, or financial sentiment.  \\nscore: 0                                                                          1\n",
              "reasoning: the article discusses potential cost savings and better outcomes from prostate surgery at specialized centers, which is a positive outlook on medical outcomes but does not mention stock prices, market conditions, or investment sentiment.  \\nscore: 0    1\n",
              "reasoning: the text describes an \"uptick in spending,\" \"nearly $20 million\" raised, and the candidate being \"in a strong position,\" which indicates favorable conditions and a positive outlook.  \\nscore: 1                                                            1\n",
              "reasoning: the text is a purely factual report on military air strikes with no mention of any stocks, financial markets, prices, or economic conditions.\\nscore: 0                                                                                                      1\n",
              "reasoning: the text reports a factual military procurement decision without any explicit claims about stock price movement, outlook, or financial performance for the involved companies.  \\nscore: 0                                                                   1\n",
              "reasoning: the text reports on a prison fight in guatemala with no mention of stocks, markets, prices, or any financial sentiment whatsoever.  \\nscore: 0                                                                                                               1\n",
              "reasoning: the text discusses donald trump's political aspirations and a new year's call, with no mention of stocks, market prices, outlooks, or financial conditions.\\nscore: 0                                                                                        1\n",
              "reasoning: the article discusses geopolitical conflict and violence with no mention of financial markets, stock prices, or economic conditions related to stocks.  \\nscore: 0                                                                                           1\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_labeled['llm_response'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load Pre-trained Transformer Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e5cb67bf4aa4ff993bf6f9c4ddd74fd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f4763833274422599c9682f11a90189",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/738M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e122400b1dd6400b80535f6b65ca3bba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/368 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81aad63a54074d85bc2b389e50a41f94",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a2e268a8f7240269fb59766021f2e03",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3ba1f313f6a4b39aecb4942b5464faf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/18.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c4e96f0178304dc481ebb621c465068e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d2790e77a5f4b2698842352dff476a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26f2ee81125f410c8b081dbf3222be20",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/568M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8fc5365294b4416f8e35900ac7767142",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44e068a787c748e2bbb548309274bbc8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69aecb4e13cd492293bd343ff9f3b87f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2abbd880baa34d8bbf47c7a05696f3ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a2b81b72bdb411eacdb9cbd412264c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/286 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Models loaded successfully!\n",
            "nickmuchi model labels: {0: 'bearish', 1: 'neutral', 2: 'bullish'}\n",
            "mrm8488 model labels: {0: 'negative', 1: 'neutral', 2: 'positive'}\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Use pipelines as high-level helpers\n",
        "pipes = {\n",
        "    \"nickmuchi\": pipeline(\"text-classification\", model=\"nickmuchi/deberta-v3-base-finetuned-finance-text-classification\"),\n",
        "    \"mrm8488\": pipeline(\"text-classification\", model=\"mrm8488/deberta-v3-ft-financial-news-sentiment-analysis\")\n",
        "}\n",
        "\n",
        "print(\"Models loaded successfully!\")\n",
        "print(f\"nickmuchi model labels: {pipes['nickmuchi'].model.config.id2label}\")\n",
        "print(f\"mrm8488 model labels: {pipes['mrm8488'].model.config.id2label}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Compare Models on Sample Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "def normalize_prediction(pred, model_name):\n",
        "    \"\"\"Normalize predictions to bullish/neutral/bearish\"\"\"\n",
        "    if isinstance(pred, dict):\n",
        "        label = pred.get('label', '').lower()\n",
        "        score = pred.get('score', 0)\n",
        "    else:\n",
        "        label = str(pred).lower()\n",
        "        score = 1.0\n",
        "    \n",
        "    # Map various label formats to our three classes\n",
        "    if 'bullish' in label or 'positive' in label or 'bull' in label:\n",
        "        return 'bullish'\n",
        "    elif 'bearish' in label or 'negative' in label or 'bear' in label:\n",
        "        return 'bearish'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "\n",
        "# Test on a sample of data (e.g., first 50 rows for comparison)\n",
        "sample_size = min(50, len(df))\n",
        "test_df = df.head(sample_size).copy()\n",
        "\n",
        "if 'text' not in test_df.columns:\n",
        "    print(\"Error: 'text' column not found!\")\n",
        "    print(f\"Available columns: {test_df.columns.tolist()}\")\n",
        "else:\n",
        "    print(f\"Testing on {sample_size} samples...\")\n",
        "    \n",
        "    # Get predictions from transformer models\n",
        "    print(\"\\nGetting predictions from transformer models...\")\n",
        "    test_df['nickmuchi_pred'] = test_df['text'].apply(lambda x: normalize_prediction(pipes['nickmuchi'](x)[0], 'nickmuchi'))\n",
        "    test_df['mrm8488_pred'] = test_df['text'].apply(lambda x: normalize_prediction(pipes['mrm8488'](x)[0], 'mrm8488'))\n",
        "    \n",
        "    # Get predictions from API (with rate limiting)\n",
        "    print(\"\\nGetting predictions from API (this may take a while)...\")\n",
        "    api_predictions = []\n",
        "    for idx, text in enumerate(tqdm(test_df['text'], desc=\"API predictions\")):\n",
        "        pred = classify_with_api(text, api_key)\n",
        "        api_predictions.append(pred)\n",
        "        time.sleep(0.1)  # Rate limiting\n",
        "    \n",
        "    test_df['api_pred'] = api_predictions\n",
        "    \n",
        "    print(\"\\nPredictions completed!\")\n",
        "    print(\"\\nSample predictions:\")\n",
        "    print(test_df[['text', 'nickmuchi_pred', 'mrm8488_pred', 'api_pred']].head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare model predictions (using API as ground truth for comparison)\n",
        "print(\"=\" * 60)\n",
        "print(\"MODEL COMPARISON (using API predictions as reference)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Compare each model against API\n",
        "for model_name in ['nickmuchi', 'mrm8488']:\n",
        "    pred_col = f'{model_name}_pred'\n",
        "    accuracy = accuracy_score(test_df['api_pred'], test_df[pred_col])\n",
        "    print(f\"\\n{model_name.upper()} vs API:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"\\nClassification Report:\")\n",
        "    print(classification_report(test_df['api_pred'], test_df[pred_col], \n",
        "                              target_names=['bearish', 'bullish', 'neutral']))\n",
        "    print(f\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(test_df['api_pred'], test_df[pred_col]))\n",
        "\n",
        "# Distribution of predictions\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"PREDICTION DISTRIBUTIONS\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nAPI predictions:\")\n",
        "print(test_df['api_pred'].value_counts())\n",
        "print(\"\\nNickmuchi predictions:\")\n",
        "print(test_df['nickmuchi_pred'].value_counts())\n",
        "print(\"\\nMRM8488 predictions:\")\n",
        "print(test_df['mrm8488_pred'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Fine-tune the Best Model\n",
        "\n",
        "Based on the comparison above, we'll fine-tune the best performing model on our dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from transformers import DataCollatorWithPadding\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Determine best model (you can change this based on comparison results)\n",
        "# For now, we'll use the one with higher accuracy or choose manually\n",
        "best_model_name = \"nickmuchi\"  # Change to \"mrm8488\" if that performs better\n",
        "best_model_id = \"nickmuchi/deberta-v3-base-finetuned-finance-text-classification\" if best_model_name == \"nickmuchi\" else \"mrm8488/deberta-v3-ft-financial-news-sentiment-analysis\"\n",
        "\n",
        "print(f\"Fine-tuning model: {best_model_name} ({best_model_id})\")\n",
        "\n",
        "# Prepare data for fine-tuning\n",
        "# We'll use API predictions as labels for fine-tuning\n",
        "if 'text' not in df.columns:\n",
        "    print(\"Error: 'text' column not found!\")\n",
        "else:\n",
        "    # Get API labels for all data (or use a subset for faster training)\n",
        "    train_size = min(500, len(df))  # Use 500 samples for training\n",
        "    train_df = df.head(train_size).copy()\n",
        "    \n",
        "    print(f\"\\nGetting API labels for {train_size} training samples...\")\n",
        "    train_labels = []\n",
        "    for idx, text in enumerate(tqdm(train_df['text'], desc=\"Getting labels\")):\n",
        "        label = classify_with_api(text, api_key)\n",
        "        train_labels.append(label)\n",
        "        time.sleep(0.1)  # Rate limiting\n",
        "    \n",
        "    train_df['label'] = train_labels\n",
        "    \n",
        "    # Map labels to integers\n",
        "    label_map = {'bearish': 0, 'neutral': 1, 'bullish': 2}\n",
        "    train_df['label_id'] = train_df['label'].map(label_map)\n",
        "    \n",
        "    # Split into train and validation\n",
        "    train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "        train_df['text'].tolist(),\n",
        "        train_df['label_id'].tolist(),\n",
        "        test_size=0.2,\n",
        "        random_state=42\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nTrain samples: {len(train_texts)}\")\n",
        "    print(f\"Validation samples: {len(val_texts)}\")\n",
        "    print(f\"Label distribution - Train: {pd.Series(train_labels).value_counts().to_dict()}\")\n",
        "    print(f\"Label distribution - Val: {pd.Series(val_labels).value_counts().to_dict()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(best_model_id)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    best_model_id,\n",
        "    num_labels=3,\n",
        "    id2label={0: 'bearish', 1: 'neutral', 2: 'bullish'},\n",
        "    label2id={'bearish': 0, 'neutral': 1, 'bullish': 2}\n",
        ")\n",
        "\n",
        "# Tokenize the data\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=512)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = Dataset.from_dict({'text': train_texts, 'label': train_labels})\n",
        "val_dataset = Dataset.from_dict({'text': val_texts, 'label': val_labels})\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Data collator\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "print(\"Datasets prepared!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=f'./results/{best_model_name}_finetuned',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=100,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=f'./logs/{best_model_name}_finetuned',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        ")\n",
        "\n",
        "# Initialize trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"Starting fine-tuning...\")\n",
        "trainer.train()\n",
        "\n",
        "print(\"\\nFine-tuning completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Re-test Fine-tuned Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the fine-tuned model\n",
        "finetuned_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    f'./results/{best_model_name}_finetuned'\n",
        ")\n",
        "finetuned_tokenizer = AutoTokenizer.from_pretrained(best_model_id)\n",
        "\n",
        "# Create pipeline with fine-tuned model\n",
        "finetuned_pipe = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=finetuned_model,\n",
        "    tokenizer=finetuned_tokenizer\n",
        ")\n",
        "\n",
        "print(\"Fine-tuned model loaded!\")\n",
        "\n",
        "# Test on validation set\n",
        "print(\"\\nEvaluating on validation set...\")\n",
        "val_predictions = []\n",
        "for text in tqdm(val_texts, desc=\"Predicting\"):\n",
        "    pred = finetuned_pipe(text)[0]\n",
        "    pred_label = normalize_prediction(pred, 'finetuned')\n",
        "    val_predictions.append(pred_label)\n",
        "\n",
        "# Map validation labels back to strings\n",
        "id_to_label = {0: 'bearish', 1: 'neutral', 2: 'bullish'}\n",
        "val_labels_str = [id_to_label[label] for label in val_labels]\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(val_labels_str, val_predictions)\n",
        "print(f\"\\nFine-tuned Model Performance:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"\\nClassification Report:\")\n",
        "print(classification_report(val_labels_str, val_predictions, \n",
        "                          target_names=['bearish', 'neutral', 'bullish']))\n",
        "print(f\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(val_labels_str, val_predictions))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare original vs fine-tuned model\n",
        "print(\"=\" * 60)\n",
        "print(\"COMPARISON: Original vs Fine-tuned Model\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Get predictions from original model\n",
        "original_predictions = []\n",
        "for text in tqdm(val_texts, desc=\"Original model\"):\n",
        "    pred = pipes[best_model_name](text)[0]\n",
        "    pred_label = normalize_prediction(pred, best_model_name)\n",
        "    original_predictions.append(pred_label)\n",
        "\n",
        "print(f\"\\nOriginal {best_model_name} model accuracy: {accuracy_score(val_labels_str, original_predictions):.4f}\")\n",
        "print(f\"Fine-tuned model accuracy: {accuracy:.4f}\")\n",
        "\n",
        "print(f\"\\nOriginal model classification report:\")\n",
        "print(classification_report(val_labels_str, original_predictions, \n",
        "                          target_names=['bearish', 'neutral', 'bullish']))\n",
        "\n",
        "print(f\"\\nFine-tuned model classification report:\")\n",
        "print(classification_report(val_labels_str, val_predictions, \n",
        "                          target_names=['bearish', 'neutral', 'bullish']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test on a few examples from the full dataset\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"SAMPLE PREDICTIONS ON NEW DATA\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "test_samples = df.tail(10) if len(df) > 10 else df\n",
        "if 'text' in test_samples.columns:\n",
        "    for idx, row in test_samples.iterrows():\n",
        "        text = row['text']\n",
        "        original_pred = normalize_prediction(pipes[best_model_name](text)[0], best_model_name)\n",
        "        finetuned_pred = normalize_prediction(finetuned_pipe(text)[0], 'finetuned')\n",
        "        \n",
        "        print(f\"\\nText: {text[:150]}...\")\n",
        "        print(f\"Original {best_model_name}: {original_pred}\")\n",
        "        print(f\"Fine-tuned: {finetuned_pred}\")\n",
        "        print(\"-\" * 60)\n",
        "else:\n",
        "    print(\"'text' column not found in dataframe\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
